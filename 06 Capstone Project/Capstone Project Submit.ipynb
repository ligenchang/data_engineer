{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import TimestampType, StringType, DateType\n",
    "import  pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There is a main data source called I94 Immigration Data and this data comes from the US National Tourism and Trade Office. The original source if from https://travel.trade.gov/research/reports/i94/historical/2016.html. In file I94_SAS_Labels_Descriptions.SAS, it gives the description of this data and also lists the dimension code description such as country code and visa code. There are also some other tables which will help to create more dimension tables. SoI plan to create one file which contains all of the dimension data from imigration file so that we can easily read the data. Besides, I will create one fact table based on the immigration data. us cities demographics data will be tranformmed to dimension data. I will be using spark to process these kind of big data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df = pd.read_csv('immigration_data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "#df_spark = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"immigration_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, cicid: string, i94yr: string, i94mon: string, i94cit: string, i94res: string, i94port: string, arrdate: string, i94mode: string, i94addr: string, depdate: string, i94bir: string, i94visa: string, count: string, dtadfile: string, visapost: string, occup: string, entdepa: string, entdepd: string, entdepu: string, matflag: string, biryear: string, dtaddto: string, gender: string, insnum: string, airline: string, admnum: string, fltno: string, visatype: string]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp = spark.read.option(\"header\",\"true\").csv( '../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_temp.createOrReplaceTempView(\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport = spark.read.option(\"header\",\"true\").csv( 'airport-codes_csv.csv')\n",
    "df_airport.createOrReplaceTempView(\"airport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_clean = df_spark.dropna(how = \"any\", subset = [\"fltno\", \"gender\", \"airline\", \"depdate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 27.0|2016.0|   4.0| 101.0| 101.0|    BOS|20545.0|    1.0|     MA|20549.0|  58.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1958.0|04062016|     M|  null|     LH|9.247876383E10|00422|      B1|\n",
      "| 28.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20549.0|  56.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1960.0|04062016|     F|  null|     LH|9.247890033E10|00422|      B1|\n",
      "| 29.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20561.0|  62.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1954.0|09302016|     M|  null|     AZ|9.250378143E10|00614|      B2|\n",
      "| 30.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NJ|20578.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     M|  null|     OS|9.247020943E10|00089|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_clean.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The star schema has been choosen as it's forward and easy for use and understand. Following are the steps:\n",
    "1.convert the numeric column with string type to int type as we need to map it with related dimension tables\n",
    "2.Transform the data from labels description doc to organized dim.cfg which we can use python config parser to read it eaily\n",
    "3.Extract related dimension data from immigration table\n",
    "4.Immigration table will be served as the fact table\n",
    "5.US cities demographics data will be served as another dimension table which can join the immigration table by i94addr column\n",
    "6.Will abandon the airport codes table and temperature table as can't find the relationships between these two tables and immigration table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid = df_spark_clean.select(col(\"*\"), df_spark_clean.i94cit.cast('int').alias('i94cit_int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid = df_spark_valid.select(col(\"*\"), df_spark_valid.i94yr.cast('int').alias('i94yr_int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid = df_spark_valid.select(col(\"*\"), df_spark_valid.i94mon.cast('int').alias('i94mon_int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid = df_spark_valid.select(col(\"*\"), df_spark_valid.i94bir.cast('int').alias('i94bir_int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+----------+---------+----------+----------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|i94cit_int|i94yr_int|i94mon_int|i94bir_int|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+----------+---------+----------+----------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|       101|     2016|         4|        55|\n",
      "| 27.0|2016.0|   4.0| 101.0| 101.0|    BOS|20545.0|    1.0|     MA|20549.0|  58.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1958.0|04062016|     M|  null|     LH|9.247876383E10|00422|      B1|       101|     2016|         4|        58|\n",
      "| 28.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20549.0|  56.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1960.0|04062016|     F|  null|     LH|9.247890033E10|00422|      B1|       101|     2016|         4|        56|\n",
      "| 29.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20561.0|  62.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1954.0|09302016|     M|  null|     AZ|9.250378143E10|00614|      B2|       101|     2016|         4|        62|\n",
      "| 30.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NJ|20578.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     M|  null|     OS|9.247020943E10|00089|      B2|       101|     2016|         4|        49|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+----------+---------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_valid.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_datetime(x):\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "udf_to_datetime_sas = udf(lambda x: to_datetime(x), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid = df_spark_valid.withColumn(\"arrivedate\", udf_to_datetime_sas('arrdate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid = df_spark_valid.withColumn(\"depardate\", udf_to_datetime_sas('depdate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid = df_spark_valid.select(col(\"*\"), df_spark_valid.i94mode.cast('int').alias('i94mode_int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid = df_spark_valid.select(col(\"*\"), df_spark_valid.i94visa.cast('int').alias('i94visa_int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+----------+---------+----------+----------+----------+----------+-----------+-----------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|i94cit_int|i94yr_int|i94mon_int|i94bir_int|arrivedate| depardate|i94mode_int|i94visa_int|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+----------+---------+----------+----------+----------+----------+-----------+-----------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|       101|     2016|         4|        55|2016-04-01|2016-08-25|          1|          2|\n",
      "| 27.0|2016.0|   4.0| 101.0| 101.0|    BOS|20545.0|    1.0|     MA|20549.0|  58.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1958.0|04062016|     M|  null|     LH|9.247876383E10|00422|      B1|       101|     2016|         4|        58|2016-04-01|2016-04-05|          1|          1|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+----------+---------+----------+----------+----------+----------+-----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_valid.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_valid.createOrReplaceTempView(\"immigration_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_code_table = spark.sql(\"\"\"\n",
    "    SELECT distinct i94cit_int as code\n",
    "    FROM immigration_valid \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|code|\n",
      "+----+\n",
      "| 148|\n",
      "| 392|\n",
      "| 516|\n",
      "| 251|\n",
      "| 255|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_code_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "Config = ConfigParser()\n",
    "Config.read('dim.cfg')\n",
    "def from_code(mysection, mykey):\n",
    "    myvalue = \"\"\n",
    "    try:\n",
    "        myvalue = Config[mysection][str(mykey)].replace(\"'\",\"\")\n",
    "    except:\n",
    "        myvalue = \"N/A\"\n",
    "    return myvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_countrycode = udf(lambda x: from_code(\"country\", x), StringType())\n",
    "country_table = country_code_table.withColumn(\"country\", get_countrycode('code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|code| country|\n",
      "+----+--------+\n",
      "| 101| ALBANIA|\n",
      "| 102| ANDORRA|\n",
      "| 103| AUSTRIA|\n",
      "| 104| BELGIUM|\n",
      "| 105|BULGARIA|\n",
      "+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_table.sort(\"code\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_table.write.parquet(\"data/tables/country\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_table.createOrReplaceTempView(\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port_code_table = spark.sql(\"\"\"\n",
    "    SELECT distinct i94port as code\n",
    "    FROM immigration_valid \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_portcode = udf(lambda x: from_code(\"port\", \"'\"+x+\"'\"), StringType())\n",
    "port_table = port_code_table.withColumn(\"port\", get_portcode('code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|code|                port|\n",
      "+----+--------------------+\n",
      "| FMY|FORT MYERS, FL   ...|\n",
      "| BGM|BANGOR, ME       ...|\n",
      "| HEL|HELENA, MT       ...|\n",
      "| FOK|  SUFFOLK COUNTY, NY|\n",
      "| SNA|SAN ANTONIO, TX  ...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port_table.write.parquet(\"data/tables/port\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port_table.createOrReplaceTempView(\"port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "mode_code_table = spark.sql(\"\"\"\n",
    "    SELECT distinct i94mode_int as code\n",
    "    FROM immigration_valid \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|code|\n",
      "+----+\n",
      "|   1|\n",
      "|   3|\n",
      "|   9|\n",
      "|   2|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mode_code_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_modecode = udf(lambda x: from_code(\"mode\", x), StringType())\n",
    "mode_table = mode_code_table.withColumn(\"mode\", get_modecode('code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|code|        mode|\n",
      "+----+------------+\n",
      "|   1|         Air|\n",
      "|   3|        Land|\n",
      "|   9|Not reported|\n",
      "|   2|         Sea|\n",
      "+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mode_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "mode_table.write.parquet(\"data/tables/mode\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "mode_table.createOrReplaceTempView(\"mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_code_table = spark.sql(\"\"\"\n",
    "    SELECT distinct i94visa_int as code\n",
    "    FROM immigration_valid \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|code|\n",
      "+----+\n",
      "|   1|\n",
      "|   3|\n",
      "|   2|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visa_code_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_visacode = udf(lambda x: from_code(\"visa\", x), StringType())\n",
    "visa_table = visa_code_table.withColumn(\"visa\", get_visacode('code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|code|    visa|\n",
      "+----+--------+\n",
      "|   1|Business|\n",
      "|   3| Student|\n",
      "|   2|Pleasure|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visa_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_table.write.parquet(\"data/tables/visa\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_table.createOrReplaceTempView(\"visa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_cities = spark.read.option(\"header\",\"true\").option(\"delimiter\", \";\").csv( 'us-cities-demographics.csv')\n",
    "df_cities.createOrReplaceTempView(\"cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cities.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_code_table = spark.sql(\"\"\"\n",
    "    SELECT distinct i94addr as code\n",
    "    FROM immigration_valid \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_code_table.createOrReplaceTempView(\"states_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|code|\n",
      "+----+\n",
      "|  .N|\n",
      "|  CI|\n",
      "|  TC|\n",
      "|  SC|\n",
      "|  AZ|\n",
      "|  NS|\n",
      "|  SL|\n",
      "|  LA|\n",
      "|  NL|\n",
      "|  MN|\n",
      "|  NK|\n",
      "|  OI|\n",
      "|  AA|\n",
      "|  NJ|\n",
      "|  MX|\n",
      "|   F|\n",
      "|  JF|\n",
      "|  DC|\n",
      "|  CN|\n",
      "|  OR|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_code_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_code_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "states_table = spark.sql(\"\"\"\n",
    "SELECT states_code.code, avg(cities.`Median Age`) as Median_Age, sum(cities.`Total Population`) as Total_Population\n",
    "FROM cities inner join states_code on (cities.`State Code` = states_code.code) group by states_code.code\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+----------------+\n",
      "|code|        Median_Age|Total_Population|\n",
      "+----+------------------+----------------+\n",
      "|  SC| 33.82500000000001|       2586976.0|\n",
      "|  AZ| 35.03750000000002|      2.249771E7|\n",
      "|  LA| 34.62500000000001|       6502975.0|\n",
      "|  MN|35.579629629629636|       7044165.0|\n",
      "|  NJ|35.254385964912295|       6931024.0|\n",
      "+----+------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "states_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "states_table.write.parquet(\"data/tables/states\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "date_table = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    arrivedate as date, \n",
    "    day(arrivedate) AS day,\n",
    "    weekofyear(arrivedate) AS week,\n",
    "    month(arrivedate) AS month,\n",
    "    year(arrivedate) AS year, \n",
    "    weekday(arrivedate) AS weekday \n",
    "FROM (\n",
    "    SELECT DISTINCT arrivedate \n",
    "    FROM immigration_valid     \n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----+-----+----+-------+\n",
      "|      date|day|week|month|year|weekday|\n",
      "+----------+---+----+-----+----+-------+\n",
      "|2016-04-25| 25|  17|    4|2016|      0|\n",
      "|2016-04-22| 22|  16|    4|2016|      4|\n",
      "|2016-04-30| 30|  17|    4|2016|      5|\n",
      "|2016-04-26| 26|  17|    4|2016|      1|\n",
      "|2016-04-04|  4|  14|    4|2016|      0|\n",
      "|2016-04-16| 16|  15|    4|2016|      5|\n",
      "|2016-04-18| 18|  16|    4|2016|      0|\n",
      "|2016-04-11| 11|  15|    4|2016|      0|\n",
      "|2016-04-29| 29|  17|    4|2016|      4|\n",
      "|2016-04-19| 19|  16|    4|2016|      1|\n",
      "|2016-04-14| 14|  15|    4|2016|      3|\n",
      "|2016-04-08|  8|  14|    4|2016|      4|\n",
      "|2016-04-02|  2|  13|    4|2016|      5|\n",
      "|2016-04-20| 20|  16|    4|2016|      2|\n",
      "|2016-04-13| 13|  15|    4|2016|      2|\n",
      "|2016-04-09|  9|  14|    4|2016|      5|\n",
      "|2016-04-17| 17|  15|    4|2016|      6|\n",
      "|2016-04-01|  1|  13|    4|2016|      4|\n",
      "|2016-04-07|  7|  14|    4|2016|      3|\n",
      "|2016-04-12| 12|  15|    4|2016|      1|\n",
      "+----------+---+----+-----+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_table = spark.sql(\"\"\"\n",
    "SELECT i94yr_int as year, i94mon_int as month, i94cit_int as citizenship, i94port as port, i94mode_int as mode, i94addr as state,  arrivedate, depardate, i94visa_int as visa, i94bir_int as age, airline, fltno, visatype\n",
    "FROM immigration_valid\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+----+----+-----+----------+----------+----+---+-------+-----+--------+\n",
      "|year|month|citizenship|port|mode|state|arrivedate| depardate|visa|age|airline|fltno|visatype|\n",
      "+----+-----+-----------+----+----+-----+----------+----------+----+---+-------+-----+--------+\n",
      "|2016|    4|        101| WAS|   1|   MI|2016-04-01|2016-08-25|   2| 55|     OS|   93|      B2|\n",
      "|2016|    4|        101| BOS|   1|   MA|2016-04-01|2016-04-05|   1| 58|     LH|00422|      B1|\n",
      "|2016|    4|        101| ATL|   1|   MA|2016-04-01|2016-04-05|   1| 56|     LH|00422|      B1|\n",
      "|2016|    4|        101| ATL|   1|   MA|2016-04-01|2016-04-17|   2| 62|     AZ|00614|      B2|\n",
      "|2016|    4|        101| ATL|   1|   NJ|2016-04-01|2016-05-04|   2| 49|     OS|00089|      B2|\n",
      "|2016|    4|        101| ATL|   1|   NY|2016-04-01|2016-06-06|   2| 43|     OS|00089|      B2|\n",
      "|2016|    4|        101| HOU|   1|   TX|2016-04-01|2016-04-10|   2| 53|     TK|00033|      B2|\n",
      "|2016|    4|        101| NYC|   1|   NJ|2016-04-01|2016-04-17|   2| 37|     TK|00001|      B2|\n",
      "|2016|    4|        101| NYC|   1|   NJ|2016-04-01|2016-04-23|   2| 49|     AZ|00608|      B2|\n",
      "|2016|    4|        101| NYC|   1|   NY|2016-04-01|2016-05-01|   2| 33|     AZ|00608|      B2|\n",
      "|2016|    4|        101| MIA|   1|   FL|2016-04-01|2016-04-30|   2| 65|     TK|00077|      B2|\n",
      "|2016|    4|        101| CHI|   1|   IL|2016-04-01|2016-04-10|   1| 35|     OS|00065|      B1|\n",
      "|2016|    4|        101| CHI|   1|   IL|2016-04-01|2016-04-18|   1| 32|     OS|00065|      B1|\n",
      "|2016|    4|        101| CHI|   1|   IL|2016-04-01|2016-05-06|   1| 38|     TK|00005|      B1|\n",
      "|2016|    4|        101| NYC|   1|   NJ|2016-04-01|2016-07-30|   3| 28|     AY|00005|      F1|\n",
      "|2016|    4|        101| NYC|   1|   NY|2016-04-01|2016-04-28|   2| 68|     AA|00199|      B2|\n",
      "|2016|    4|        101| NYC|   1|   NY|2016-04-01|2016-04-28|   2| 61|     AA|00199|      B2|\n",
      "|2016|    4|        101| NYC|   1|   MI|2016-04-01|2016-04-19|   2| 41|     AZ|00610|      B2|\n",
      "|2016|    4|        101| MIA|   1|   FL|2016-04-01|2016-04-11|   2| 45|     AA|00207|      B2|\n",
      "|2016|    4|        101| NYC|   1|   NY|2016-04-01|2016-04-14|   2| 54|     AB|07450|      B2|\n",
      "+----+-----+-----------+----+----+-----+----------+----------+----+---+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[year: int, month: int, citizenship: int, port: string, mode: int, state: string, arrivedate: date, depardate: date, visa: int, age: int, airline: string, fltno: string, visatype: string]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_table = immigration_table.withColumn(\"immigration_id\", F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+----+----+-----+----------+----------+----+---+-------+-----+--------+--------------+\n",
      "|year|month|citizenship|port|mode|state|arrivedate| depardate|visa|age|airline|fltno|visatype|immigration_id|\n",
      "+----+-----+-----------+----+----+-----+----------+----------+----+---+-------+-----+--------+--------------+\n",
      "|2016|    4|        101| WAS|   1|   MI|2016-04-01|2016-08-25|   2| 55|     OS|   93|      B2|             0|\n",
      "|2016|    4|        101| BOS|   1|   MA|2016-04-01|2016-04-05|   1| 58|     LH|00422|      B1|             1|\n",
      "|2016|    4|        101| ATL|   1|   MA|2016-04-01|2016-04-05|   1| 56|     LH|00422|      B1|             2|\n",
      "|2016|    4|        101| ATL|   1|   MA|2016-04-01|2016-04-17|   2| 62|     AZ|00614|      B2|             3|\n",
      "|2016|    4|        101| ATL|   1|   NJ|2016-04-01|2016-05-04|   2| 49|     OS|00089|      B2|             4|\n",
      "|2016|    4|        101| ATL|   1|   NY|2016-04-01|2016-06-06|   2| 43|     OS|00089|      B2|             5|\n",
      "|2016|    4|        101| HOU|   1|   TX|2016-04-01|2016-04-10|   2| 53|     TK|00033|      B2|             6|\n",
      "|2016|    4|        101| NYC|   1|   NJ|2016-04-01|2016-04-17|   2| 37|     TK|00001|      B2|             7|\n",
      "|2016|    4|        101| NYC|   1|   NJ|2016-04-01|2016-04-23|   2| 49|     AZ|00608|      B2|             8|\n",
      "|2016|    4|        101| NYC|   1|   NY|2016-04-01|2016-05-01|   2| 33|     AZ|00608|      B2|             9|\n",
      "|2016|    4|        101| MIA|   1|   FL|2016-04-01|2016-04-30|   2| 65|     TK|00077|      B2|            10|\n",
      "|2016|    4|        101| CHI|   1|   IL|2016-04-01|2016-04-10|   1| 35|     OS|00065|      B1|            11|\n",
      "|2016|    4|        101| CHI|   1|   IL|2016-04-01|2016-04-18|   1| 32|     OS|00065|      B1|            12|\n",
      "|2016|    4|        101| CHI|   1|   IL|2016-04-01|2016-05-06|   1| 38|     TK|00005|      B1|            13|\n",
      "|2016|    4|        101| NYC|   1|   NJ|2016-04-01|2016-07-30|   3| 28|     AY|00005|      F1|            14|\n",
      "|2016|    4|        101| NYC|   1|   NY|2016-04-01|2016-04-28|   2| 68|     AA|00199|      B2|            15|\n",
      "|2016|    4|        101| NYC|   1|   NY|2016-04-01|2016-04-28|   2| 61|     AA|00199|      B2|            16|\n",
      "|2016|    4|        101| NYC|   1|   MI|2016-04-01|2016-04-19|   2| 41|     AZ|00610|      B2|            17|\n",
      "|2016|    4|        101| MIA|   1|   FL|2016-04-01|2016-04-11|   2| 45|     AA|00207|      B2|            18|\n",
      "|2016|    4|        101| NYC|   1|   NY|2016-04-01|2016-04-14|   2| 54|     AB|07450|      B2|            19|\n",
      "+----+-----+-----------+----+----+-----+----------+----------+----+---+-------+-----+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_table.write.partitionBy(\"month\", \"state\").parquet(\"data/tables/immigration\", 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "loop every table and verify that there is data in the table after the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality on table country check passed\n",
      "Data quality on table port check passed\n",
      "Data quality on table immigration_valid check passed\n"
     ]
    }
   ],
   "source": [
    "for mytable in [\"country\", \"port\", \"immigration_valid\", \"visa\", \"mode\"]:\n",
    "            mode_code_table = spark.sql(\"SELECT * FROM \"+ mytable)\n",
    "            count =   mode_code_table.count()                            \n",
    "            if count < 1:\n",
    "                raise ValueError(f\"Data quality check failed. {mytable} returned no results\")\n",
    "            print(f\"Data quality on table {mytable} check passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "immigration table:\n",
    "\n",
    "    year: 4 digit year for entering US \n",
    "    \n",
    "    month: digitial month for entering US \n",
    "\n",
    "    citizenship: immigrant's original citizenship\n",
    "\n",
    "    port: port of entry \n",
    "\n",
    "    arrivedate: immigrant's arrive date \n",
    "\n",
    "    depardate: immigrant's depart date \n",
    "\n",
    "    age: immigrant's age\n",
    "\n",
    "    visa: immigrant's visa category\n",
    "\n",
    "    airline: immigrant's airline \n",
    "\n",
    "    fltno: immigrant's flight number \n",
    "\n",
    "    visatype: immigrant's visa type such as B1, B2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "date table:\n",
    "\n",
    "    date: the date\n",
    "    \n",
    "    day: which day of the year\n",
    "    \n",
    "    week: which week of the year\n",
    "    \n",
    "    month: which month of the year\n",
    "    \n",
    "    year: year number\n",
    "    \n",
    "    weekday: is weekday or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "states table:\n",
    "\n",
    "    code: State Code \n",
    "\n",
    "    Median_Age: Average of Median Age\n",
    "\n",
    "    Total_Population: Total Population in the state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "visa table:\n",
    "\n",
    "    code: visa category code\n",
    "    \n",
    "    visa: visa category description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "mode table:\n",
    "\n",
    "    code: mode code\n",
    "    \n",
    "    mode: enter mode e.g. air or land"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "port table:\n",
    "\n",
    "    code: port code\n",
    "    \n",
    "    port: port name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "country table:\n",
    "\n",
    "    code: country code\n",
    "    \n",
    "    country: country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1.Spark is meant for big data sets that cannot fit on one computer. AS the data increase, we need one mechamism to deal with the big task that one computer could not handle. As the immigration data is so large and it also keeps increasing to time, so that I think spark is one good choice for that.\n",
    "2.As the data accuracy requirement is not too high, I think the data update frequency should be monthly. If daily, that will be a bit too frequent.\n",
    "3.If the data size was increased 100 times, I think I will still choose spark. But when save the immigration parquet, I will choose different ways to partition it. If the data needs to populate in dashboard on daily basis, I will implement airflow to control the schedule and task dependencies. If the database needs to be accesses by 100+ people, the postgresql will be one good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
