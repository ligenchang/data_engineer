{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import TimestampType, StringType\n",
    "import  pyspark.sql.functions as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# config = configparser.ConfigParser()\n",
    "\n",
    "# config.read_file(open('dl.cfg'))\n",
    "\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= \"AKIAVVYXCZ5YGKK5RHL4\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data = \"s3a://udacity-dend/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_data = os.path.join(input_data, \"log_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read log data file\n",
    "df = spark.read.json(input_data + \"log_data/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.filter(df[\"page\"] != \"NextSong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+-------------+--------+------+-----+--------------------+------+-----+-----------------+---------+----+------+-------------+--------------------+------+\n",
      "|artist|      auth|firstName|gender|itemInSession|lastName|length|level|            location|method| page|     registration|sessionId|song|status|           ts|           userAgent|userId|\n",
      "+------+----------+---------+------+-------------+--------+------+-----+--------------------+------+-----+-----------------+---------+----+------+-------------+--------------------+------+\n",
      "|  null| Logged In|    Wyatt|     M|            0|   Scott|  null| free|Eureka-Arcata-For...|   GET| Home|1.540872073796E12|      563|null|   200|1542247071796|Mozilla/5.0 (Wind...|     9|\n",
      "|  null| Logged In|   Austin|     M|            0| Rosales|  null| free|New York-Newark-J...|   GET| Home|1.541059521796E12|      521|null|   200|1542252577796|Mozilla/5.0 (Wind...|    12|\n",
      "|  null| Logged In|   Samuel|     M|            1|Gonzalez|  null| free|Houston-The Woodl...|   GET|About|1.540492941796E12|      597|null|   200|1542253460796|\"Mozilla/5.0 (Mac...|    61|\n",
      "|  null|Logged Out|     null|  null|            0|    null|  null| paid|                null|   PUT|Login|             null|      602|null|   307|1542260074796|                null|      |\n",
      "|  null| Logged In|    Tegan|     F|            1|  Levine|  null| paid|Portland-South Po...|   GET| Home|1.540794356796E12|      602|null|   200|1542260277796|\"Mozilla/5.0 (Mac...|    80|\n",
      "+------+----------+---------+------+-------------+--------+------+-----+--------------------+------+-----+-----------------+---------+----+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda x: datetime.fromtimestamp(x/1000), TimestampType())\n",
    "df = df.withColumn(\"start_time\", get_timestamp('ts'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+------+-------------+--------+------+-----+--------------------+------+-----+-----------------+---------+----+------+-------------+--------------------+------+--------------------+\n",
      "|artist|      auth|firstName|gender|itemInSession|lastName|length|level|            location|method| page|     registration|sessionId|song|status|           ts|           userAgent|userId|          start_time|\n",
      "+------+----------+---------+------+-------------+--------+------+-----+--------------------+------+-----+-----------------+---------+----+------+-------------+--------------------+------+--------------------+\n",
      "|  null| Logged In|    Wyatt|     M|            0|   Scott|  null| free|Eureka-Arcata-For...|   GET| Home|1.540872073796E12|      563|null|   200|1542247071796|Mozilla/5.0 (Wind...|     9|2018-11-15 01:57:...|\n",
      "|  null| Logged In|   Austin|     M|            0| Rosales|  null| free|New York-Newark-J...|   GET| Home|1.541059521796E12|      521|null|   200|1542252577796|Mozilla/5.0 (Wind...|    12|2018-11-15 03:29:...|\n",
      "|  null| Logged In|   Samuel|     M|            1|Gonzalez|  null| free|Houston-The Woodl...|   GET|About|1.540492941796E12|      597|null|   200|1542253460796|\"Mozilla/5.0 (Mac...|    61|2018-11-15 03:44:...|\n",
      "|  null|Logged Out|     null|  null|            0|    null|  null| paid|                null|   PUT|Login|             null|      602|null|   307|1542260074796|                null|      |2018-11-15 05:34:...|\n",
      "|  null| Logged In|    Tegan|     F|            1|  Levine|  null| paid|Portland-South Po...|   GET| Home|1.540794356796E12|      602|null|   200|1542260277796|\"Mozilla/5.0 (Mac...|    80|2018-11-15 05:37:...|\n",
      "+------+----------+---------+------+-------------+--------+------+-----+--------------------+------+-----+-----------------+---------+----+------+-------------+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, artist: string, auth: string, firstName: string, gender: string, itemInSession: string, lastName: string, length: string, level: string, location: string, method: string, page: string, registration: string, sessionId: string, song: string, status: string, ts: string, userAgent: string, userId: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns for users table    \n",
    "users_table = spark.sql(\"\"\"\n",
    "SELECT DISTINCT userId as user_id, firstName as first_name, lastName as last_name, gender, level, location, userAgent\n",
    "FROM logs\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-479d9e2f524c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# write users table to parquet files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0musers_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3a://micudacity1/tables/users\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# write users table to parquet files\n",
    "users_table.write.parquet(\"s3a://micudacity1/tables/users\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create time table\n",
    "time_table = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    start_time, \n",
    "    hour(start_time) AS hour,\n",
    "    day(start_time) AS day,\n",
    "    weekofyear(start_time) AS week,\n",
    "    month(start_time) AS month,\n",
    "    year(start_time) AS year, \n",
    "    weekday(start_time) AS weekday \n",
    "FROM (\n",
    "    SELECT DISTINCT cast(ts/1000 as TIMESTAMP) as start_time \n",
    "    FROM logs     \n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-15 16:12:...|  16| 15|  46|   11|2018|      3|\n",
      "|2018-11-26 18:25:...|  18| 26|  48|   11|2018|      0|\n",
      "|2018-11-06 05:49:...|   5|  6|  45|   11|2018|      1|\n",
      "|2018-11-28 10:25:...|  10| 28|  48|   11|2018|      2|\n",
      "|2018-11-28 18:24:...|  18| 28|  48|   11|2018|      2|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table.createOrReplaceTempView(\"time_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table.write.partitionBy(\"year\", \"month\").parquet(\"data/tables/time\", 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in song data to use for songplays table\n",
    "#song_df = spark.read.json(\"s3a://udacity-dend/song_data/*/*/*/*.json\")\n",
    "song_df = spark.read.json(\"s3a://udacity-dend/song_data/*/*/*/*.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table = spark.sql(\"\"\"\n",
    "    SELECT distinct song_id, title, artist_id, year, duration\n",
    "    FROM songs\n",
    "\"\"\")\n",
    "songs_table.createOrReplaceTempView(\"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table \n",
    "songplays_table = spark.sql(\"\"\"\n",
    "SELECT logs.start_time, time_table.year, time_table.month, userId as user_id, level, song_id, artist_id, sessionId as session_id, location, userAgent\n",
    "FROM logs left join songs on (logs.song = songs.title)\n",
    "join time_table on (time_table.start_time = logs.start_time)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table = songplays_table.withColumn(\"songplay_id\", F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+-------+-----+-------+---------+----------+--------------------+--------------------+-----------+\n",
      "|          start_time|year|month|user_id|level|song_id|artist_id|session_id|            location|           userAgent|songplay_id|\n",
      "+--------------------+----+-----+-------+-----+-------+---------+----------+--------------------+--------------------+-----------+\n",
      "|2018-11-15 01:57:...|2018|   11|      9| free|   null|     null|       563|Eureka-Arcata-For...|Mozilla/5.0 (Wind...|          0|\n",
      "|2018-11-15 03:29:...|2018|   11|     12| free|   null|     null|       521|New York-Newark-J...|Mozilla/5.0 (Wind...|          1|\n",
      "|2018-11-15 03:44:...|2018|   11|     61| free|   null|     null|       597|Houston-The Woodl...|\"Mozilla/5.0 (Mac...|          2|\n",
      "|2018-11-15 05:34:...|2018|   11|       | paid|   null|     null|       602|                null|                null|          3|\n",
      "|2018-11-15 05:37:...|2018|   11|     80| paid|   null|     null|       602|Portland-South Po...|\"Mozilla/5.0 (Mac...|          4|\n",
      "+--------------------+----+-----+-------+-----+-------+---------+----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.getOrCreate()\n",
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfSong = spark.read.json(\"data/song_data/*/*/*/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|  artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|                 |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "|AREBBGV1187FB523D2|           null|      Houston, TX|            null|Mike Jones (Featu...|173.66159|        1|SOOLYAZ12A6701F4A6|Laws Patrolling (...|   0|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|Morris Plains, NJ|       -74.47995|The Dillinger Esc...|207.77751|        1|SOBBUGU12A8C13E95D|Setting Fire to S...|2004|\n",
      "|ARPBNLO1187FB3D52F|       40.71455|     New York, NY|       -74.00712|            Tiny Tim| 43.36281|        1|SOAOIBZ12AB01815BE|I Hold Your Hand ...|2000|\n",
      "|ARDNS031187B9924F0|       32.67828|          Georgia|       -83.22295|          Tim Wilson|186.48771|        1|SONYPOM12A8C13B2D7|I Think My Wife I...|2005|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSong.printSchema()\n",
    "dfSong.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfSong.createOrReplaceTempView(\"songs\")\n",
    "df_song_table = spark.sql(\"\"\"\n",
    "    SELECT distinct song_id, title, artist_id, year, duration\n",
    "    FROM songs\n",
    "\"\"\")\n",
    "df_song_table.write.partitionBy(\"year\", \"artist_id\").parquet(\"data/tables/songs\", 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_artist_table = spark.sql(\"\"\"\n",
    "    SELECT distinct artist_id, artist_name as name, artist_location as location, artist_latitude as latitude, artist_longitude longitude\n",
    "    FROM songs\n",
    "\"\"\")\n",
    "df_artist_table.write.parquet(\"data/tables/artists\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+---------------+--------+----------+\n",
      "|         artist_id|        name|       location|latitude| longitude|\n",
      "+------------------+------------+---------------+--------+----------+\n",
      "|ARPBNLO1187FB3D52F|    Tiny Tim|   New York, NY|40.71455| -74.00712|\n",
      "|ARBEBBY1187B9B43DB|   Tom Petty|Gainesville, FL|    null|      null|\n",
      "|AR0IAWL1187B9A96D0|Danilo Perez|         Panama|  8.4177| -80.11278|\n",
      "|ARMBR4Y1187B9990EB|David Martin|California - SF|37.77916|-122.42005|\n",
      "|ARD0S291187B9B7BF5|     Rated R|           Ohio|    null|      null|\n",
      "+------------------+------------+---------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_artist_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, artist_id: string, name: string, location: string, latitude: string, longitude: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artist_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(\"data/log-data/*.json\")\n",
    "df = df.withColumn(\"play_time\", F.to_timestamp(\"ts\"))\n",
    "df.createOrReplaceTempView(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+--------------------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|           song|status|           ts|           userAgent|userId|           play_time|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+--------------------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|  Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|50841-09-12 03:26...|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|50841-09-19 17:23...|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|50841-09-22 17:36...|\n",
      "|       null|Logged In|    Wyatt|     M|            0|   Scott|     null| free|Eureka-Arcata-For...|   GET|    Home|1.540872073796E12|      563|           null|   200|1542247071796|Mozilla/5.0 (Wind...|     9|50841-11-11 20:23...|\n",
      "|       null|Logged In|   Austin|     M|            0| Rosales|     null| free|New York-Newark-J...|   GET|    Home|1.541059521796E12|      521|           null|   200|1542252577796|Mozilla/5.0 (Wind...|    12|50842-01-14 13:49...|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import  pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay_table = spark.sql(\"\"\"\n",
    "    SELECT ts as start_time, userId as user_id, level, song_id, artist_id, sessionId as session_id, location, userAgent\n",
    "    FROM songs, logs WHERE logs.song = songs.title\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_songplay_table = df_songplay_table.withColumn(\"songplay_id\", F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+-----------+\n",
      "|   start_time|user_id|level|           song_id|         artist_id|session_id|            location|           userAgent|songplay_id|\n",
      "+-------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+-----------+\n",
      "|1542837407796|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|          0|\n",
      "|1542171963796|     10| free|SOGDBUF12A8C140FAA|AR558FS1187FB45658|       484|Washington-Arling...|\"Mozilla/5.0 (Mac...|          1|\n",
      "|1542618860796|     24| paid|SOGDBUF12A8C140FAA|AR558FS1187FB45658|       672|Lake Havasu City-...|\"Mozilla/5.0 (Win...|          2|\n",
      "|1543358159796|     80| paid|SOGDBUF12A8C140FAA|AR558FS1187FB45658|       992|Portland-South Po...|\"Mozilla/5.0 (Mac...|          3|\n",
      "+-------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_songplay_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_user_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT userId as user_id, firstName as first_name, lastName as last_name, gender, level, location, userAgent\n",
    "    FROM logs\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+--------------------+--------------------+\n",
      "|user_id|first_name|last_name|gender|level|            location|           userAgent|\n",
      "+-------+----------+---------+------+-----+--------------------+--------------------+\n",
      "|     51|      Maia|    Burke|     F| free|Houston-The Woodl...|\"Mozilla/5.0 (Win...|\n",
      "|     94|      Noah|   Chavez|     M| free|Ogden-Clearfield, UT|Mozilla/5.0 (Wind...|\n",
      "|     24|     Layla|  Griffin|     F| paid|Lake Havasu City-...|\"Mozilla/5.0 (Win...|\n",
      "|     59|      Lily|   Cooper|     F| free|        Columbia, SC|\"Mozilla/5.0 (Win...|\n",
      "|      4|    Alivia|  Terrell|     F| free|Parkersburg-Vienn...|\"Mozilla/5.0 (Win...|\n",
      "+-------+----------+---------+------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_time_table = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    start_time, \n",
    "    hour(start_time) AS hour,\n",
    "    day(start_time) AS day,\n",
    "    weekofyear(start_time) AS week,\n",
    "    month(start_time) AS month,\n",
    "    year(start_time) AS year, \n",
    "    weekday(start_time) AS weekday \n",
    "FROM (\n",
    "    SELECT DISTINCT cast(ts/1000 as TIMESTAMP) as start_time \n",
    "    FROM logs     \n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-15 16:12:...|  16| 15|  46|   11|2018|      3|\n",
      "|2018-11-21 06:18:...|   6| 21|  47|   11|2018|      2|\n",
      "|2018-11-21 18:49:...|  18| 21|  47|   11|2018|      2|\n",
      "|2018-11-14 15:20:...|  15| 14|  46|   11|2018|      2|\n",
      "|2018-11-05 16:31:...|  16|  5|  45|   11|2018|      0|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
